{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import argparse\n",
    "\n",
    "\n",
    "# folder_path = 'model1/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "# os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "\n",
    "def f_1(x):\n",
    "    return x[:, 0] + 0.25 * x[:, 1] ** 2+0.1*torch.tanh(0.5*x[:,2]-0.3)\n",
    "\n",
    "# def f_2(x):\n",
    "#     return x[:,0]**2/2-abs(x[:,4]*x[:,9])+torch.exp(0.1*x[:,14])-torch.sin(3.141592*x[:,19])\n",
    "# def f_2(x):\n",
    "#     return 2*(x[:,0]>0)-2*(x[:,0]<0)\n",
    "\n",
    "def poisson_loss(logits,y_true):\n",
    "    \"\"\"\n",
    "    Compute the Poisson negative log-likelihood loss.\n",
    "    \n",
    "    Args:\n",
    "        y_true (torch.Tensor): True labels (0, 1, 2, ...), shape (batch_size,).\n",
    "        logits (torch.Tensor): Output of the DNN (before exponentiation), shape (batch_size,).\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Mean negative log-likelihood loss over the batch.\n",
    "    \"\"\"\n",
    "    # Convert logits to λ(x) = e^logits\n",
    "    lambda_pred = torch.exp(logits)\n",
    "    \n",
    "    # Compute the negative log-likelihood\n",
    "    loss = lambda_pred - y_true * logits  # Equivalent to λ(x) - Y * log(λ(x))\n",
    "    return loss.mean()\n",
    "\n",
    "class SampleSet:\n",
    "    def __init__(self, n, p,f_X,module='Bernoulli', mean=0, std=1,trials=None):\n",
    "        \"\"\"\n",
    "        Initializes the SampleSet with n samples and p features for X.\n",
    "        Y is generated based on the conditional probability P(Y=1|X).\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "        self.p = p\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.r=None\n",
    "        self.B=None\n",
    "        self.module=module\n",
    "        # Generate X with dimension (n, p)\n",
    "        X_main = torch.normal(0.0, 1.0, size=(n, 2))\n",
    "        X_noise = torch.normal(0.0, 1, size=(n, p - 2))\n",
    "        self.X = torch.cat([X_main, X_noise], dim=1)\n",
    "        # self.X=2*torch.rand((n, p)) -2\n",
    "        self.subtrain=None\n",
    "        self.subval=None\n",
    "        self.counts=None\n",
    "        self.trials=trials\n",
    "        self.f_X=f_X\n",
    "        # Compute z = f(X) and use it to generate P(Y=1|X) and Y\n",
    "        self.z = self._compute_z(self.X)  # Save z values (f(X))\n",
    "        self.Y = self._generate_Y(self.z)\n",
    "    \n",
    "    def _compute_z(self, X):\n",
    "        return   self.f_X(X)\n",
    "    \n",
    "    def _generate_Y(self, z):\n",
    "        if self.module=='Bernoulli':\n",
    "            # Generate Y as a Bernoulli random variable with probability P(Y=1|X)\n",
    "            P_Y_given_X = 1 / (1 + torch.exp(-z))\n",
    "            Y = torch.bernoulli(P_Y_given_X)\n",
    "        elif self.module=='Gaussian':\n",
    "            Y = torch.normal(mean=z, std=1.0)\n",
    "        elif self.module=='Binomial':\n",
    "            if self.trials is None:\n",
    "                self.trials = torch.randint(low=5, high=6, size=(self.n,))  \n",
    "\n",
    "            P_Y_given_X = 1 / (1 + torch.exp(-z)) # Ensure the rate parameter is positive\n",
    "            Y = torch.binomial(self.trials.float(), P_Y_given_X)\n",
    "\n",
    "        elif self.module == 'Poisson':\n",
    "        # Generate Y as a Poisson random variable with rate parameter (lambda) equal to exp(z)\n",
    "            rate_param = torch.log(1+torch.exp(z))   # Ensure the rate parameter is positive\n",
    "            Y = torch.poisson(rate_param)\n",
    "        else:\n",
    "        # Raise an error for unsupported modules\n",
    "            raise ValueError(f\"Unsupported module type: {self.module}. Expected one of: 'Bernoulli', 'Gaussian', 'Exponential', 'Poisson'.\")\n",
    "        return Y\n",
    "    \n",
    "    def get_z(self):\n",
    "        \"\"\"Returns the computed z values, which represent f(X).\"\"\"\n",
    "        return self.z\n",
    "    \n",
    "    def get_sample_set(self):\n",
    "        \"\"\"Returns the main sample set (X, Y).\"\"\"\n",
    "        return self.X, self.Y\n",
    "    \n",
    "    def get_sub_samples_with_validation(self, B, r):\n",
    "        \"\"\"\n",
    "        Generates B sub-sample sets, each containing r samples randomly selected \n",
    "        from the main sample set, along with corresponding validation sets.\n",
    "        \n",
    "        Also counts the number of times each index is selected across all B sub-samples.\n",
    "        \n",
    "        Returns:\n",
    "            train_samples: List of tuples, each containing (train_X, train_Y, train_indices)\n",
    "            validation_samples: List of tuples, each containing (val_X, val_Y, val_indices)\n",
    "            selection_counts: Dictionary with counts of each index's appearance in the B sub-samples.\n",
    "        \"\"\"\n",
    "        train_samples = []\n",
    "        validation_samples = []\n",
    "        selection_counts = Counter({i: 0 for i in range(self.n)})  # To track appearances of each index\n",
    "        indices = torch.arange(self.n)\n",
    "        self.B=B\n",
    "        self.r=r\n",
    "        for _ in range(B):\n",
    "            # Randomly select r unique indices for the sub-sample\n",
    "            selected_indices = indices[torch.randperm(self.n)[:r]]\n",
    "            \n",
    "            # Update selection count for each index\n",
    "            selection_counts.update(selected_indices.tolist())\n",
    "            \n",
    "            # Get validation indices (those not in selected_indices)\n",
    "            val_indices = torch.tensor([i for i in indices if i not in selected_indices])\n",
    "\n",
    "            # Separate sub-sample and validation sets, including original indices\n",
    "            X_sub = self.X[selected_indices]\n",
    "            Y_sub = self.Y[selected_indices]\n",
    "            X_val = self.X[val_indices]\n",
    "            Y_val = self.Y[val_indices]\n",
    "            \n",
    "            # Append to train_samples and validation_samples lists\n",
    "            train_samples.append((X_sub, Y_sub, selected_indices))\n",
    "            validation_samples.append((X_val, Y_val, val_indices))\n",
    "        self.subtrain=train_samples\n",
    "        self.subval=validation_samples\n",
    "        self.counts=dict(selection_counts)\n",
    "        return train_samples, validation_samples, dict(selection_counts)\n",
    "    \n",
    "    def save(self, file_path):\n",
    "        \"\"\"Saves the SampleSet instance to a file.\"\"\"\n",
    "        torch.save(self, file_path)\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(file_path):\n",
    "        \"\"\"Loads a SampleSet instance from a file.\"\"\"\n",
    "        return torch.load(file_path)\n",
    "\n",
    "\n",
    "\n",
    "def clear_folder(folder_path):\n",
    "    \"\"\"\n",
    "    删除文件夹中的所有内容，但保留文件夹本身\n",
    "    :param folder_path: 文件夹路径\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"文件夹 {folder_path} 不存在\")\n",
    "        return\n",
    "\n",
    "    # 遍历文件夹中的内容\n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        # 如果是文件，直接删除\n",
    "        if os.path.isfile(item_path):\n",
    "            os.remove(item_path)\n",
    "        # 如果是文件夹，递归删除整个文件夹\n",
    "        elif os.path.isdir(item_path):\n",
    "            shutil.rmtree(item_path)\n",
    "\n",
    "    print(f\"已清空文件夹 {folder_path} 的所有内容\")\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, dropout_rate=0.0):\n",
    "        \"\"\"\n",
    "        Defines a neural network with three layers: two hidden layers with dropout and one output layer.\n",
    "        The output is a single scalar, representing the approximation of f(X).\n",
    "        \"\"\"\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)  # Dropout after the first hidden layer\n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)  # Dropout after the second hidden layer\n",
    "        self.output = nn.Linear(hidden_size2, 1)  # Single output for f(X)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = self.dropout1(x)  # Apply dropout after first hidden layer\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.dropout2(x)  # Apply dropout after second hidden layer\n",
    "        x = self.output(x)  # Output is a single logit (for binary classification)\n",
    "        return x\n",
    "\n",
    "def train_network(network, train_loader,mode=\"Bernoulli\", num_epochs=100, learning_rate=0.1,weight_decay=0.05,tol=0.0001,patience=7):\n",
    "    if mode == \"Bernoulli\":\n",
    "        criterion = nn.BCEWithLogitsLoss() \n",
    "    elif mode==\"Poisson\":\n",
    "        criterion=poisson_loss\n",
    "    else:\n",
    "    # Raise an error for unsupported modules\n",
    "        raise ValueError(f\"Unsupported module type {mode}. Expected one of: 'Bernoulli', 'Gaussian', 'Exponential', 'Poisson'.\")\n",
    "    \n",
    "    # BCELossWithLogits combines sigmoid and binary cross-entropy in one function\n",
    "    length=len(train_loader.dataset)\n",
    "    optimizer = optim.SGD(network.parameters(), lr=learning_rate,weight_decay=weight_decay)\n",
    "    prev_epoch_loss = None  \n",
    "    stable_count=0 \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0  \n",
    "        for batch_X, batch_Y in train_loader:\n",
    "            # Forward pass\n",
    "            logits = network(batch_X).squeeze() # Get scalar logits, shape (batch_size)\n",
    "            # print(torch.max(logits))  \n",
    "            loss = criterion(logits, batch_Y.float())  # Y needs to be float for BCELossWithLogits\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "    # Compute average loss for the epoch\n",
    "        epoch_loss = running_loss / length\n",
    "        # print(f\"Epoch {epoch}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "        # Early‐stop check\n",
    "        if prev_epoch_loss is not None:\n",
    "            delta = abs(prev_epoch_loss - epoch_loss)\n",
    "            if delta < tol:\n",
    "                stable_count += 1\n",
    "            else:\n",
    "                stable_count = 0  # 重置计数\n",
    "\n",
    "            if stable_count >= patience:\n",
    "                print(f\"Early stop at epoch {epoch} after {patience} stable epochs with loss {epoch_loss}.\")\n",
    "                break\n",
    "        prev_epoch_loss = epoch_loss\n",
    "    print(f\"With loss {epoch_loss}.\")\n",
    "\n",
    "# Instantiate and train B neural networks, one for each sub-sample\n",
    "def train_multiple_networks(sample_set, input_size, hidden_size1, hidden_size2,mode=\"Bernoulli\",batchsize=64, dropout_rate=0.1, num_epochs=100, learning_rate=0.01,weight_decay=0.05,tol=0.0001,patience=7):\n",
    "    train_samples, validation_samples, selection_counts = sample_set.subtrain, sample_set.subval, sample_set.counts\n",
    "    \n",
    "    networks = []  # List to hold trained neural networks\n",
    "    for i, (train_data, val_data) in enumerate(zip(train_samples, validation_samples)):\n",
    "        X_sub, Y_sub, _ = train_data\n",
    "        X_val, Y_val, _ = val_data\n",
    "\n",
    "        \n",
    "        # Prepare data loader for this sub-sample\n",
    "        train_dataset = TensorDataset(X_sub, Y_sub)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "        \n",
    "        # Instantiate a new network for this sub-sample\n",
    "        network = NeuralNetwork(input_size, hidden_size1, hidden_size2, dropout_rate=dropout_rate)\n",
    "        # print(f\"\\nTraining network {i+1}/{B} on sub-sample {i+1}\")\n",
    "        \n",
    "        # Train the network on the current sub-sample\n",
    "        train_network(network, train_loader,mode=mode, num_epochs=num_epochs, learning_rate=learning_rate,weight_decay=weight_decay,tol=tol,patience=patience)\n",
    "        \n",
    "        # Append the trained network to the list of networks\n",
    "        networks.append(network)\n",
    "\n",
    "        # Validation performance (optional)\n",
    "        with torch.no_grad():\n",
    "            if mode==\"Bernoulli\":\n",
    "                logits = network(X_val).squeeze()\n",
    "                true_logits=f_1(X_val)\n",
    "                accuracy = (torch.sign(logits) == torch.sign(true_logits)).float().mean() * 100\n",
    "                print(f\"Validation Accuracy for network {i+1}: {accuracy.item():.2f}%\")\n",
    "                print(torch.mean(abs(logits-true_logits)))\n",
    "\n",
    "            elif mode == \"Poisson\":\n",
    "                logits = network(X_val).squeeze()\n",
    "                # print(torch.max(logits))\n",
    "                true_lambda=torch.log(1+torch.exp(f_1(X_val)))\n",
    "                estimated_lambda=torch.exp(logits)\n",
    "                print(f\" network {i+1}: {torch.max(true_lambda),torch.min(true_lambda)}%\")\n",
    "                # print(torch.max(estimated_lambda))\n",
    "                # print(torch.max(true_lambda-estimated_lambda),torch.min(true_lambda-estimated_lambda))\n",
    "                print(torch.mean(abs(true_lambda-estimated_lambda)),torch.std(abs(true_lambda-estimated_lambda)))\n",
    "                # print(torch.mean(estimated_lambda))\n",
    "          \n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported module type {mode}. Expected one of: 'Bernoulli', 'Gaussian', 'Exponential', 'Poisson'.\")\n",
    "\n",
    "\n",
    "    \n",
    "    return networks\n",
    "\n",
    "\n",
    "\n",
    "# def ensemble_predict_batch_f(Xtest, networks,sample_set):\n",
    "#     ntest = Xtest.shape[0]\n",
    "#     n = sample_set.n  # Total number of original samples\n",
    "#     r = sample_set.r  # Size of each sub-sample\n",
    "#     B = len(networks)  # Number of sub-samples (number of neural networks)\n",
    "#     # Prepare a tensor to store all network outputs (shape: [ntest, B])\n",
    "#     all_outputs = torch.zeros(ntest, B)\n",
    "#     # Step 1: Compute the average prediction (log-odds) for each xtest sample across all networks\n",
    "#     with torch.no_grad():  # Disable gradient computation for inference\n",
    "#         for i, network in enumerate(networks):\n",
    "#             logits = network(Xtest).squeeze(1)  # Get logits for all test samples (shape: [ntest])\n",
    "#             all_outputs[:, i] = logits  # Store the logits from each network in the i-th column\n",
    "#     # Step 2: Compute J_bji and J_.i for each index i\n",
    "#     J_bji = sample_set.counts  # This is J_bji as a dictionary from SampleSet\n",
    "\n",
    "#     J_dot_i = {i: J_bji[i]/B for i in range(n)}  # J_.i = mean of J_bji across B\n",
    "#     # Average the logits across the B networks to get ensemble logits\n",
    "\n",
    "#     # Step 3: Compute Cov_i,* for each index i and each test sample in xtest\n",
    "#     hatf_B=all_outputs.mean(dim=1)\n",
    "#     sigma_squared_star_f = torch.zeros(ntest)  # Initialize covariance estimate for each test sample\n",
    "#     for i in range(n):\n",
    "#         cov_i_star = torch.zeros(ntest)\n",
    "#         correction_i_star=torch.zeros(ntest)\n",
    "#         for j in range(B):\n",
    "#             _,_,Jbjicount=sample_set.subtrain[j]\n",
    "\n",
    "#             J_bji_value = 1 if i in Jbjicount else 0  # Indicator if index i is in sub-sample j\n",
    "#             deviations = all_outputs[:, j] - hatf_B  # Deviation of each network's prediction from the mean, shape: (ntest,)\n",
    "#             cov_i_star += (J_bji_value - J_dot_i[i]) * deviations / B \n",
    "        \n",
    "#         # Sum cov_i_values over all B sub-samples for index i, then square and sum for all i\n",
    "#         sigma_squared_star_f += cov_i_star.pow(2) \n",
    "#     # print(sigma_squared_star_f)\n",
    "#     print(sum(deviations**2))\n",
    "#     # factor=(n-1)/n*(n/(n-r))**2\n",
    "#     factor=(n-1)/n*(n/(n-r))**2\n",
    "#     var_f=factor*sigma_squared_star_f\n",
    "#     sd_f=torch.sqrt(var_f)\n",
    "#     upper_f=(hatf_B+1.96*sd_f)\n",
    "#     lower_f=(hatf_B-1.96*sd_f)\n",
    "\n",
    "\n",
    "\n",
    "#     return all_outputs, [hatf_B,sd_f,upper_f,lower_f]#,[probabilities_h,sd_h,upper_h,lower_h]    # based on average over f or h\n",
    "\n",
    "\n",
    "\n",
    "def ensemble_predict_batch_f(Xtest, networks, sample_set):\n",
    "    ntest = Xtest.shape[0]\n",
    "    n = sample_set.n       # Total number of original samples\n",
    "    r = sample_set.r       # Size of each sub-sample\n",
    "    B = len(networks)      # Number of sub-samples (number of neural networks)\n",
    "\n",
    "    # Collect logits from all networks for the test set (shape: [ntest, B])\n",
    "    all_outputs = torch.zeros(ntest, B)\n",
    "    with torch.no_grad():\n",
    "        for j, net in enumerate(networks):\n",
    "            logits = net(Xtest).squeeze(1)\n",
    "            all_outputs[:, j] = logits\n",
    "\n",
    "    # Compute inclusion counts J_bji and mean inclusion J_dot_i for each training index i\n",
    "    J_bji = sample_set.counts  # Dict mapping i -> count of i in each sub-sample\n",
    "    J_dot_i = {i: J_bji[i] / B for i in range(n)}\n",
    "\n",
    "    # Ensemble mean prediction for each test sample\n",
    "    hatf_B = all_outputs.mean(dim=1)  # Shape: [ntest]\n",
    "\n",
    "    # Initialize accumulators for variance correction terms\n",
    "    sum_V2 = torch.zeros(ntest)      # Accumulate sum of hat_V_i^2 over i\n",
    "    sum_Zdiff2 = torch.zeros(ntest)  # Accumulate sum of (Z_ji - hat_V_i)^2 over i and j\n",
    "\n",
    "    # Loop over each original data index i\n",
    "    for i in range(n):\n",
    "        # Gather Z_{b_j i}(x*) for all sub-samples j (shape: [B, ntest])\n",
    "        Zs = torch.zeros(B, ntest)\n",
    "        for j in range(B):\n",
    "            _, _, Jbjicount = sample_set.subtrain[j]\n",
    "            in_subset = 1.0 if (i in Jbjicount) else 0.0\n",
    "            deviations = all_outputs[:, j] - hatf_B  # Shape: [ntest]\n",
    "            Zs[j] = (in_subset - J_dot_i[i]) * deviations\n",
    "\n",
    "        # Compute hat_V_i(x*) and accumulate\n",
    "        hat_V_i = Zs.mean(dim=0)  # Shape: [ntest]\n",
    "        sum_V2 += hat_V_i.pow(2)\n",
    "        sum_Zdiff2 += (Zs - hat_V_i.unsqueeze(0)).pow(2).sum(dim=0)\n",
    "\n",
    "    # Correction factor: n(n-1)/(n-r)^2\n",
    "    factor = (n - 1) / n * (n / (n - r))**2\n",
    "\n",
    "    # Compute corrected variance terms\n",
    "    term1 = factor * sum_V2\n",
    "    term2 = factor * sum_Zdiff2 / (B * (B - 1))\n",
    "    var_f = term1 - term2          # Bias-corrected variance estimate\n",
    "\n",
    "    # Standard deviations\n",
    "    sd_f_raw = torch.sqrt(term1)       # Without bias correction\n",
    "    sd_f_correct = torch.sqrt(var_f)   # With bias correction\n",
    "\n",
    "\n",
    "    return all_outputs, [hatf_B, sd_f_raw, sd_f_correct]\n",
    "\n",
    "\n",
    "\n",
    "def run_one_repeat(rep_id, n, r, B, p, GLM_name, f_1, xtest):\n",
    "    # 每个 repeat 训练 B 个网络，最后做一次 ensemble 预测\n",
    "    ss = SampleSet(n, p, f_1, module=GLM_name)\n",
    "    ss.get_sub_samples_with_validation(B, r)\n",
    "\n",
    "    networks = train_multiple_networks(\n",
    "        ss,\n",
    "        input_size=p,\n",
    "        hidden_size1=128,\n",
    "        hidden_size2=64,\n",
    "        mode=GLM_name,\n",
    "        batchsize=r,\n",
    "        num_epochs=500,\n",
    "        learning_rate=0.1,\n",
    "        weight_decay=0.02,\n",
    "        dropout_rate=0.1,\n",
    "        tol=0.0001,\n",
    "        patience=4\n",
    "    )\n",
    "\n",
    "    Af, Bf = ensemble_predict_batch_f(xtest, networks, ss)\n",
    "    return Af,Bf[0], Bf[1],Bf[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With loss 0.4796035885810852.\n",
      "Validation Accuracy for network 1: 85.16%\n",
      "tensor(0.4845)\n",
      "With loss 0.510231614112854.\n",
      "Validation Accuracy for network 2: 89.02%\n",
      "tensor(0.4737)\n",
      "With loss 0.5041273832321167.\n",
      "Validation Accuracy for network 3: 87.24%\n",
      "tensor(0.4434)\n",
      "With loss 0.49597710371017456.\n",
      "Validation Accuracy for network 4: 89.91%\n",
      "tensor(0.4218)\n",
      "With loss 0.48313942551612854.\n",
      "Validation Accuracy for network 5: 85.76%\n",
      "tensor(0.5161)\n",
      "With loss 0.5034325122833252.\n",
      "Validation Accuracy for network 6: 87.54%\n",
      "tensor(0.4488)\n",
      "With loss 0.4858100116252899.\n",
      "Validation Accuracy for network 7: 86.94%\n",
      "tensor(0.4528)\n",
      "With loss 0.4597313404083252.\n",
      "Validation Accuracy for network 8: 86.05%\n",
      "tensor(0.5457)\n",
      "With loss 0.524151623249054.\n",
      "Validation Accuracy for network 9: 87.24%\n",
      "tensor(0.4166)\n",
      "With loss 0.479556679725647.\n",
      "Validation Accuracy for network 10: 82.20%\n",
      "tensor(0.5881)\n",
      "With loss 0.5140072107315063.\n",
      "Validation Accuracy for network 11: 85.76%\n",
      "tensor(0.4512)\n",
      "With loss 0.4488527774810791.\n",
      "Validation Accuracy for network 12: 87.83%\n",
      "tensor(0.5679)\n",
      "With loss 0.49252957105636597.\n",
      "Validation Accuracy for network 13: 89.91%\n",
      "tensor(0.4636)\n",
      "With loss 0.4861712157726288.\n",
      "Validation Accuracy for network 14: 83.09%\n",
      "tensor(0.5146)\n",
      "With loss 0.49969929456710815.\n",
      "Validation Accuracy for network 15: 90.21%\n",
      "tensor(0.4638)\n",
      "With loss 0.5196598172187805.\n",
      "Validation Accuracy for network 16: 85.16%\n",
      "tensor(0.4014)\n",
      "With loss 0.518866240978241.\n",
      "Validation Accuracy for network 17: 89.32%\n",
      "tensor(0.3960)\n",
      "With loss 0.5314013361930847.\n",
      "Validation Accuracy for network 18: 84.87%\n",
      "tensor(0.4432)\n",
      "With loss 0.5259400606155396.\n",
      "Validation Accuracy for network 19: 91.69%\n",
      "tensor(0.3859)\n",
      "With loss 0.49586498737335205.\n",
      "Validation Accuracy for network 20: 86.94%\n",
      "tensor(0.4793)\n",
      "With loss 0.4884856641292572.\n",
      "Validation Accuracy for network 21: 89.32%\n",
      "tensor(0.5256)\n",
      "With loss 0.4694362282752991.\n",
      "Validation Accuracy for network 22: 84.87%\n",
      "tensor(0.5191)\n",
      "With loss 0.5316188931465149.\n",
      "Validation Accuracy for network 23: 88.43%\n",
      "tensor(0.3954)\n",
      "With loss 0.5051335692405701.\n",
      "Validation Accuracy for network 24: 88.72%\n",
      "tensor(0.3801)\n",
      "With loss 0.5041975378990173.\n",
      "Validation Accuracy for network 25: 85.46%\n",
      "tensor(0.4520)\n",
      "With loss 0.4980337917804718.\n",
      "Validation Accuracy for network 26: 86.94%\n",
      "tensor(0.4675)\n",
      "With loss 0.52088862657547.\n",
      "Validation Accuracy for network 27: 86.65%\n",
      "tensor(0.4007)\n",
      "With loss 0.4727189540863037.\n",
      "Validation Accuracy for network 28: 88.72%\n",
      "tensor(0.5460)\n",
      "With loss 0.5153367519378662.\n",
      "Validation Accuracy for network 29: 89.02%\n",
      "tensor(0.4212)\n",
      "With loss 0.5085580945014954.\n",
      "Validation Accuracy for network 30: 84.57%\n",
      "tensor(0.4838)\n",
      "With loss 0.5088307857513428.\n",
      "Validation Accuracy for network 31: 83.38%\n",
      "tensor(0.5609)\n",
      "With loss 0.49247586727142334.\n",
      "Validation Accuracy for network 32: 86.65%\n",
      "tensor(0.4312)\n",
      "With loss 0.47097232937812805.\n",
      "Validation Accuracy for network 33: 89.91%\n",
      "tensor(0.4354)\n",
      "With loss 0.5000560879707336.\n",
      "Validation Accuracy for network 34: 83.98%\n",
      "tensor(0.5317)\n",
      "With loss 0.5046982765197754.\n",
      "Validation Accuracy for network 35: 79.82%\n",
      "tensor(0.5436)\n",
      "With loss 0.4574149549007416.\n",
      "Validation Accuracy for network 36: 84.57%\n",
      "tensor(0.5134)\n",
      "With loss 0.49848443269729614.\n",
      "Validation Accuracy for network 37: 85.76%\n",
      "tensor(0.5615)\n",
      "With loss 0.4722805917263031.\n",
      "Validation Accuracy for network 38: 87.54%\n",
      "tensor(0.4641)\n",
      "With loss 0.4681120216846466.\n",
      "Validation Accuracy for network 39: 83.68%\n",
      "tensor(0.5268)\n",
      "With loss 0.47275641560554504.\n",
      "Validation Accuracy for network 40: 82.79%\n",
      "tensor(0.5704)\n",
      "With loss 0.4875052273273468.\n",
      "Validation Accuracy for network 41: 83.98%\n",
      "tensor(0.5256)\n",
      "With loss 0.5286321043968201.\n",
      "Validation Accuracy for network 42: 86.05%\n",
      "tensor(0.3892)\n",
      "With loss 0.5171774625778198.\n",
      "Validation Accuracy for network 43: 91.10%\n",
      "tensor(0.3910)\n",
      "With loss 0.5108920335769653.\n",
      "Validation Accuracy for network 44: 84.27%\n",
      "tensor(0.4667)\n",
      "With loss 0.4717773497104645.\n",
      "Validation Accuracy for network 45: 86.35%\n",
      "tensor(0.4660)\n",
      "With loss 0.4856632649898529.\n",
      "Validation Accuracy for network 46: 87.83%\n",
      "tensor(0.4896)\n",
      "With loss 0.5300155878067017.\n",
      "Validation Accuracy for network 47: 85.16%\n",
      "tensor(0.4065)\n",
      "With loss 0.48441362380981445.\n",
      "Validation Accuracy for network 48: 84.27%\n",
      "tensor(0.5240)\n",
      "With loss 0.52131587266922.\n",
      "Validation Accuracy for network 49: 84.87%\n",
      "tensor(0.4176)\n",
      "With loss 0.49832120537757874.\n",
      "Validation Accuracy for network 50: 84.57%\n",
      "tensor(0.4449)\n",
      "With loss 0.508683443069458.\n",
      "Validation Accuracy for network 51: 87.54%\n",
      "tensor(0.4047)\n",
      "With loss 0.4775806665420532.\n",
      "Validation Accuracy for network 52: 89.61%\n",
      "tensor(0.5120)\n",
      "With loss 0.5007234811782837.\n",
      "Validation Accuracy for network 53: 86.94%\n",
      "tensor(0.4486)\n",
      "With loss 0.4464883804321289.\n",
      "Validation Accuracy for network 54: 81.01%\n",
      "tensor(0.6312)\n",
      "With loss 0.5075796246528625.\n",
      "Validation Accuracy for network 55: 84.27%\n",
      "tensor(0.4051)\n",
      "With loss 0.47020092606544495.\n",
      "Validation Accuracy for network 56: 88.13%\n",
      "tensor(0.5285)\n",
      "With loss 0.500953197479248.\n",
      "Validation Accuracy for network 57: 89.91%\n",
      "tensor(0.3712)\n",
      "With loss 0.47635719180107117.\n",
      "Validation Accuracy for network 58: 84.27%\n",
      "tensor(0.4865)\n",
      "With loss 0.4629647731781006.\n",
      "Validation Accuracy for network 59: 88.13%\n",
      "tensor(0.5434)\n",
      "With loss 0.469248503446579.\n",
      "Validation Accuracy for network 60: 82.20%\n",
      "tensor(0.5746)\n",
      "With loss 0.5232534408569336.\n",
      "Validation Accuracy for network 61: 82.79%\n",
      "tensor(0.4424)\n",
      "With loss 0.4747908115386963.\n",
      "Validation Accuracy for network 62: 86.35%\n",
      "tensor(0.4779)\n",
      "With loss 0.5249513387680054.\n",
      "Validation Accuracy for network 63: 87.54%\n",
      "tensor(0.4191)\n",
      "With loss 0.48464712500572205.\n",
      "Validation Accuracy for network 64: 87.54%\n",
      "tensor(0.4773)\n",
      "With loss 0.5196142196655273.\n",
      "Validation Accuracy for network 65: 88.13%\n",
      "tensor(0.4035)\n",
      "With loss 0.5307161808013916.\n",
      "Validation Accuracy for network 66: 84.87%\n",
      "tensor(0.4728)\n",
      "With loss 0.4878096282482147.\n",
      "Validation Accuracy for network 67: 87.24%\n",
      "tensor(0.5021)\n",
      "With loss 0.4577997028827667.\n",
      "Validation Accuracy for network 68: 84.87%\n",
      "tensor(0.4557)\n",
      "With loss 0.5381782650947571.\n",
      "Validation Accuracy for network 69: 84.27%\n",
      "tensor(0.4528)\n",
      "With loss 0.5192696452140808.\n",
      "Validation Accuracy for network 70: 84.27%\n",
      "tensor(0.4192)\n",
      "With loss 0.5268374085426331.\n",
      "Validation Accuracy for network 71: 84.27%\n",
      "tensor(0.4742)\n",
      "With loss 0.49525606632232666.\n",
      "Validation Accuracy for network 72: 82.20%\n",
      "tensor(0.5368)\n",
      "With loss 0.48039522767066956.\n",
      "Validation Accuracy for network 73: 89.02%\n",
      "tensor(0.4237)\n",
      "With loss 0.5293014049530029.\n",
      "Validation Accuracy for network 74: 80.71%\n",
      "tensor(0.4939)\n",
      "With loss 0.4611453115940094.\n",
      "Validation Accuracy for network 75: 89.91%\n",
      "tensor(0.5285)\n",
      "With loss 0.48964324593544006.\n",
      "Validation Accuracy for network 76: 89.02%\n",
      "tensor(0.5360)\n",
      "With loss 0.4692476689815521.\n",
      "Validation Accuracy for network 77: 86.65%\n",
      "tensor(0.5330)\n",
      "With loss 0.488860160112381.\n",
      "Validation Accuracy for network 78: 84.87%\n",
      "tensor(0.5421)\n",
      "With loss 0.49914810061454773.\n",
      "Validation Accuracy for network 79: 86.35%\n",
      "tensor(0.4994)\n",
      "With loss 0.5038103461265564.\n",
      "Validation Accuracy for network 80: 90.50%\n",
      "tensor(0.4195)\n",
      "With loss 0.5204958319664001.\n",
      "Validation Accuracy for network 81: 87.24%\n",
      "tensor(0.3962)\n",
      "With loss 0.5231235027313232.\n",
      "Validation Accuracy for network 82: 88.72%\n",
      "tensor(0.3914)\n",
      "With loss 0.4777745008468628.\n",
      "Validation Accuracy for network 83: 85.16%\n",
      "tensor(0.5125)\n",
      "With loss 0.5058253407478333.\n",
      "Validation Accuracy for network 84: 85.16%\n",
      "tensor(0.4683)\n",
      "With loss 0.49726536870002747.\n",
      "Validation Accuracy for network 85: 86.35%\n",
      "tensor(0.5172)\n",
      "With loss 0.5165696144104004.\n",
      "Validation Accuracy for network 86: 85.16%\n",
      "tensor(0.4281)\n",
      "With loss 0.4983866512775421.\n",
      "Validation Accuracy for network 87: 86.35%\n",
      "tensor(0.4222)\n",
      "With loss 0.49033740162849426.\n",
      "Validation Accuracy for network 88: 86.05%\n",
      "tensor(0.4785)\n",
      "With loss 0.5228362083435059.\n",
      "Validation Accuracy for network 89: 87.24%\n",
      "tensor(0.4105)\n",
      "With loss 0.47986793518066406.\n",
      "Validation Accuracy for network 90: 88.72%\n",
      "tensor(0.4681)\n",
      "With loss 0.4754381477832794.\n",
      "Validation Accuracy for network 91: 84.57%\n",
      "tensor(0.4740)\n",
      "With loss 0.525704026222229.\n",
      "Validation Accuracy for network 92: 82.79%\n",
      "tensor(0.5230)\n",
      "With loss 0.486579567193985.\n",
      "Validation Accuracy for network 93: 86.35%\n",
      "tensor(0.4572)\n",
      "With loss 0.5081981420516968.\n",
      "Validation Accuracy for network 94: 86.65%\n",
      "tensor(0.4912)\n",
      "With loss 0.470333456993103.\n",
      "Validation Accuracy for network 95: 86.05%\n",
      "tensor(0.5180)\n",
      "With loss 0.5176457762718201.\n",
      "Validation Accuracy for network 96: 86.35%\n",
      "tensor(0.4299)\n",
      "With loss 0.4853437542915344.\n",
      "Validation Accuracy for network 97: 88.13%\n",
      "tensor(0.4345)\n",
      "With loss 0.481395959854126.\n",
      "Validation Accuracy for network 98: 88.13%\n",
      "tensor(0.4450)\n",
      "With loss 0.4682907164096832.\n",
      "Validation Accuracy for network 99: 83.98%\n",
      "tensor(0.5300)\n",
      "With loss 0.5013599991798401.\n",
      "Validation Accuracy for network 100: 89.91%\n",
      "tensor(0.3818)\n",
      "With loss 0.4807027280330658.\n",
      "Validation Accuracy for network 101: 89.02%\n",
      "tensor(0.4753)\n",
      "With loss 0.4926583468914032.\n",
      "Validation Accuracy for network 102: 84.27%\n",
      "tensor(0.4521)\n",
      "With loss 0.528019905090332.\n",
      "Validation Accuracy for network 103: 84.87%\n",
      "tensor(0.4426)\n",
      "With loss 0.49876800179481506.\n",
      "Validation Accuracy for network 104: 86.05%\n",
      "tensor(0.4434)\n",
      "With loss 0.47243332862854004.\n",
      "Validation Accuracy for network 105: 82.49%\n",
      "tensor(0.5608)\n",
      "With loss 0.5081475377082825.\n",
      "Validation Accuracy for network 106: 86.35%\n",
      "tensor(0.4509)\n",
      "With loss 0.4941043555736542.\n",
      "Validation Accuracy for network 107: 87.24%\n",
      "tensor(0.4467)\n",
      "With loss 0.5073656439781189.\n",
      "Validation Accuracy for network 108: 87.24%\n",
      "tensor(0.4820)\n",
      "With loss 0.4932243824005127.\n",
      "Validation Accuracy for network 109: 88.72%\n",
      "tensor(0.4564)\n",
      "With loss 0.4908769726753235.\n",
      "Validation Accuracy for network 110: 88.43%\n",
      "tensor(0.4133)\n",
      "With loss 0.48763740062713623.\n",
      "Validation Accuracy for network 111: 88.72%\n",
      "tensor(0.4236)\n",
      "With loss 0.4992281198501587.\n",
      "Validation Accuracy for network 112: 88.43%\n",
      "tensor(0.4483)\n",
      "With loss 0.5165023803710938.\n",
      "Validation Accuracy for network 113: 83.38%\n",
      "tensor(0.4766)\n",
      "With loss 0.5372852087020874.\n",
      "Validation Accuracy for network 114: 91.10%\n",
      "tensor(0.3755)\n",
      "With loss 0.496337890625.\n",
      "Validation Accuracy for network 115: 85.16%\n",
      "tensor(0.4536)\n",
      "With loss 0.5048763155937195.\n",
      "Validation Accuracy for network 116: 83.68%\n",
      "tensor(0.4747)\n",
      "With loss 0.47683748602867126.\n",
      "Validation Accuracy for network 117: 86.05%\n",
      "tensor(0.5222)\n",
      "With loss 0.5276906490325928.\n",
      "Validation Accuracy for network 118: 88.13%\n",
      "tensor(0.3515)\n",
      "With loss 0.4827596843242645.\n",
      "Validation Accuracy for network 119: 87.24%\n",
      "tensor(0.4707)\n",
      "With loss 0.5069246888160706.\n",
      "Validation Accuracy for network 120: 89.61%\n",
      "tensor(0.4202)\n",
      "With loss 0.48094332218170166.\n",
      "Validation Accuracy for network 121: 89.02%\n",
      "tensor(0.5376)\n",
      "With loss 0.5137025117874146.\n",
      "Validation Accuracy for network 122: 86.35%\n",
      "tensor(0.4405)\n",
      "With loss 0.5104112029075623.\n",
      "Validation Accuracy for network 123: 87.24%\n",
      "tensor(0.4722)\n",
      "With loss 0.4987547993659973.\n",
      "Validation Accuracy for network 124: 82.79%\n",
      "tensor(0.4500)\n",
      "With loss 0.5171970129013062.\n",
      "Validation Accuracy for network 125: 88.13%\n",
      "tensor(0.4034)\n",
      "With loss 0.4757966995239258.\n",
      "Validation Accuracy for network 126: 87.24%\n",
      "tensor(0.4743)\n",
      "With loss 0.4948406517505646.\n",
      "Validation Accuracy for network 127: 89.02%\n",
      "tensor(0.4355)\n",
      "With loss 0.47045642137527466.\n",
      "Validation Accuracy for network 128: 86.35%\n",
      "tensor(0.5305)\n",
      "With loss 0.4967961609363556.\n",
      "Validation Accuracy for network 129: 85.76%\n",
      "tensor(0.4413)\n",
      "With loss 0.49692776799201965.\n",
      "Validation Accuracy for network 130: 86.65%\n",
      "tensor(0.4362)\n",
      "With loss 0.519024670124054.\n",
      "Validation Accuracy for network 131: 86.65%\n",
      "tensor(0.4210)\n",
      "With loss 0.49608996510505676.\n",
      "Validation Accuracy for network 132: 87.54%\n",
      "tensor(0.4500)\n",
      "With loss 0.4809686839580536.\n",
      "Validation Accuracy for network 133: 83.38%\n",
      "tensor(0.5030)\n",
      "With loss 0.49272218346595764.\n",
      "Validation Accuracy for network 134: 83.98%\n",
      "tensor(0.4784)\n",
      "With loss 0.5080204606056213.\n",
      "Validation Accuracy for network 135: 87.54%\n",
      "tensor(0.4425)\n",
      "With loss 0.4915298521518707.\n",
      "Validation Accuracy for network 136: 89.32%\n",
      "tensor(0.5400)\n",
      "With loss 0.5121315121650696.\n",
      "Validation Accuracy for network 137: 87.54%\n",
      "tensor(0.4302)\n",
      "With loss 0.5048808455467224.\n",
      "Validation Accuracy for network 138: 90.21%\n",
      "tensor(0.4186)\n",
      "With loss 0.4688948392868042.\n",
      "Validation Accuracy for network 139: 84.27%\n",
      "tensor(0.5643)\n",
      "With loss 0.46527615189552307.\n",
      "Validation Accuracy for network 140: 86.05%\n",
      "tensor(0.5199)\n",
      "With loss 0.5303502082824707.\n",
      "Validation Accuracy for network 141: 85.76%\n",
      "tensor(0.4007)\n",
      "With loss 0.4959745705127716.\n",
      "Validation Accuracy for network 142: 89.32%\n",
      "tensor(0.4908)\n",
      "With loss 0.5036157369613647.\n",
      "Validation Accuracy for network 143: 87.54%\n",
      "tensor(0.4278)\n",
      "With loss 0.4810187816619873.\n",
      "Validation Accuracy for network 144: 82.20%\n",
      "tensor(0.4875)\n",
      "With loss 0.500021755695343.\n",
      "Validation Accuracy for network 145: 89.32%\n",
      "tensor(0.4026)\n",
      "With loss 0.5175142884254456.\n",
      "Validation Accuracy for network 146: 88.72%\n",
      "tensor(0.3928)\n",
      "With loss 0.5180906057357788.\n",
      "Validation Accuracy for network 147: 88.72%\n",
      "tensor(0.4242)\n",
      "With loss 0.5155141949653625.\n",
      "Validation Accuracy for network 148: 87.83%\n",
      "tensor(0.4572)\n",
      "With loss 0.4601730406284332.\n",
      "Validation Accuracy for network 149: 83.68%\n",
      "tensor(0.5639)\n",
      "With loss 0.5078973174095154.\n",
      "Validation Accuracy for network 150: 85.16%\n",
      "tensor(0.4635)\n",
      "With loss 0.5371320247650146.\n",
      "Validation Accuracy for network 151: 83.38%\n",
      "tensor(0.4755)\n",
      "With loss 0.5153558850288391.\n",
      "Validation Accuracy for network 152: 88.43%\n",
      "tensor(0.4177)\n",
      "With loss 0.4991856813430786.\n",
      "Validation Accuracy for network 153: 87.83%\n",
      "tensor(0.4461)\n",
      "With loss 0.47412100434303284.\n",
      "Validation Accuracy for network 154: 88.43%\n",
      "tensor(0.5799)\n",
      "With loss 0.48819679021835327.\n",
      "Validation Accuracy for network 155: 86.05%\n",
      "tensor(0.5525)\n",
      "With loss 0.4578256607055664.\n",
      "Validation Accuracy for network 156: 86.94%\n",
      "tensor(0.5776)\n",
      "With loss 0.5243335962295532.\n",
      "Validation Accuracy for network 157: 87.24%\n",
      "tensor(0.4192)\n",
      "With loss 0.4915701150894165.\n",
      "Validation Accuracy for network 158: 89.61%\n",
      "tensor(0.4743)\n",
      "With loss 0.48873206973075867.\n",
      "Validation Accuracy for network 159: 86.05%\n",
      "tensor(0.4861)\n",
      "With loss 0.5013937950134277.\n",
      "Validation Accuracy for network 160: 87.24%\n",
      "tensor(0.4609)\n",
      "With loss 0.4815868139266968.\n",
      "Validation Accuracy for network 161: 86.35%\n",
      "tensor(0.4980)\n",
      "With loss 0.47539108991622925.\n",
      "Validation Accuracy for network 162: 88.72%\n",
      "tensor(0.6246)\n",
      "With loss 0.49341580271720886.\n",
      "Validation Accuracy for network 163: 89.02%\n",
      "tensor(0.4731)\n",
      "With loss 0.47081196308135986.\n",
      "Validation Accuracy for network 164: 81.01%\n",
      "tensor(0.5902)\n",
      "With loss 0.48962587118148804.\n",
      "Validation Accuracy for network 165: 89.91%\n",
      "tensor(0.4133)\n",
      "With loss 0.4893486499786377.\n",
      "Validation Accuracy for network 166: 83.68%\n",
      "tensor(0.5057)\n",
      "With loss 0.44767555594444275.\n",
      "Validation Accuracy for network 167: 86.94%\n",
      "tensor(0.6346)\n",
      "With loss 0.5020771026611328.\n",
      "Validation Accuracy for network 168: 83.68%\n",
      "tensor(0.5079)\n",
      "With loss 0.4852384924888611.\n",
      "Validation Accuracy for network 169: 88.72%\n",
      "tensor(0.4359)\n",
      "With loss 0.4746692478656769.\n",
      "Validation Accuracy for network 170: 84.87%\n",
      "tensor(0.5010)\n",
      "With loss 0.48487621545791626.\n",
      "Validation Accuracy for network 171: 86.94%\n",
      "tensor(0.5116)\n",
      "With loss 0.4838225841522217.\n",
      "Validation Accuracy for network 172: 89.32%\n",
      "tensor(0.4473)\n",
      "With loss 0.4892764687538147.\n",
      "Validation Accuracy for network 173: 89.32%\n",
      "tensor(0.4575)\n",
      "With loss 0.5374680757522583.\n",
      "Validation Accuracy for network 174: 86.94%\n",
      "tensor(0.3787)\n",
      "With loss 0.507559597492218.\n",
      "Validation Accuracy for network 175: 87.83%\n",
      "tensor(0.4121)\n",
      "With loss 0.48722565174102783.\n",
      "Validation Accuracy for network 176: 84.27%\n",
      "tensor(0.5634)\n",
      "With loss 0.44458967447280884.\n",
      "Validation Accuracy for network 177: 85.16%\n",
      "tensor(0.5991)\n",
      "With loss 0.5035563111305237.\n",
      "Validation Accuracy for network 178: 86.94%\n",
      "tensor(0.4182)\n",
      "With loss 0.4984065592288971.\n",
      "Validation Accuracy for network 179: 84.27%\n",
      "tensor(0.4920)\n",
      "With loss 0.5267412662506104.\n",
      "Validation Accuracy for network 180: 85.76%\n",
      "tensor(0.3850)\n",
      "With loss 0.49604856967926025.\n",
      "Validation Accuracy for network 181: 87.24%\n",
      "tensor(0.4340)\n",
      "With loss 0.5278199911117554.\n",
      "Validation Accuracy for network 182: 86.94%\n",
      "tensor(0.4381)\n",
      "With loss 0.4948382079601288.\n",
      "Validation Accuracy for network 183: 86.35%\n",
      "tensor(0.4734)\n",
      "With loss 0.5130738615989685.\n",
      "Validation Accuracy for network 184: 88.13%\n",
      "tensor(0.4152)\n",
      "With loss 0.5109978318214417.\n",
      "Validation Accuracy for network 185: 86.05%\n",
      "tensor(0.4577)\n",
      "With loss 0.49839088320732117.\n",
      "Validation Accuracy for network 186: 82.20%\n",
      "tensor(0.5513)\n",
      "With loss 0.5018826127052307.\n",
      "Validation Accuracy for network 187: 89.02%\n",
      "tensor(0.4606)\n",
      "With loss 0.5114255547523499.\n",
      "Validation Accuracy for network 188: 86.65%\n",
      "tensor(0.3552)\n",
      "With loss 0.5092958211898804.\n",
      "Validation Accuracy for network 189: 82.79%\n",
      "tensor(0.4080)\n",
      "With loss 0.5252801179885864.\n",
      "Validation Accuracy for network 190: 83.38%\n",
      "tensor(0.4631)\n",
      "With loss 0.4621429443359375.\n",
      "Validation Accuracy for network 191: 83.98%\n",
      "tensor(0.5191)\n",
      "With loss 0.4845089614391327.\n",
      "Validation Accuracy for network 192: 86.35%\n",
      "tensor(0.4399)\n",
      "With loss 0.5305047631263733.\n",
      "Validation Accuracy for network 193: 82.20%\n",
      "tensor(0.4629)\n",
      "With loss 0.4757782816886902.\n",
      "Validation Accuracy for network 194: 84.27%\n",
      "tensor(0.5117)\n",
      "With loss 0.5047163367271423.\n",
      "Validation Accuracy for network 195: 91.10%\n",
      "tensor(0.4347)\n",
      "With loss 0.4534347653388977.\n",
      "Validation Accuracy for network 196: 84.27%\n",
      "tensor(0.5450)\n",
      "With loss 0.5043582320213318.\n",
      "Validation Accuracy for network 197: 86.05%\n",
      "tensor(0.4451)\n",
      "With loss 0.47939297556877136.\n",
      "Validation Accuracy for network 198: 88.72%\n",
      "tensor(0.4552)\n",
      "With loss 0.4862669110298157.\n",
      "Validation Accuracy for network 199: 88.13%\n",
      "tensor(0.4246)\n",
      "With loss 0.49257636070251465.\n",
      "Validation Accuracy for network 200: 88.43%\n",
      "tensor(0.4565)\n",
      "With loss 0.5147625207901001.\n",
      "Validation Accuracy for network 201: 85.16%\n",
      "tensor(0.4677)\n",
      "With loss 0.4789804518222809.\n",
      "Validation Accuracy for network 202: 87.54%\n",
      "tensor(0.4478)\n",
      "With loss 0.4807972013950348.\n",
      "Validation Accuracy for network 203: 86.35%\n",
      "tensor(0.5357)\n",
      "With loss 0.5045154094696045.\n",
      "Validation Accuracy for network 204: 86.35%\n",
      "tensor(0.4374)\n",
      "With loss 0.47689348459243774.\n",
      "Validation Accuracy for network 205: 85.76%\n",
      "tensor(0.5470)\n",
      "With loss 0.5001612305641174.\n",
      "Validation Accuracy for network 206: 84.27%\n",
      "tensor(0.5165)\n",
      "With loss 0.4802902638912201.\n",
      "Validation Accuracy for network 207: 82.79%\n",
      "tensor(0.5084)\n",
      "With loss 0.5235722661018372.\n",
      "Validation Accuracy for network 208: 90.21%\n",
      "tensor(0.3698)\n",
      "With loss 0.5240392684936523.\n",
      "Validation Accuracy for network 209: 89.32%\n",
      "tensor(0.4059)\n",
      "With loss 0.4905252158641815.\n",
      "Validation Accuracy for network 210: 90.50%\n",
      "tensor(0.4262)\n",
      "With loss 0.49168458580970764.\n",
      "Validation Accuracy for network 211: 84.87%\n",
      "tensor(0.5472)\n",
      "With loss 0.5099872350692749.\n",
      "Validation Accuracy for network 212: 89.02%\n",
      "tensor(0.4407)\n",
      "With loss 0.4739924967288971.\n",
      "Validation Accuracy for network 213: 86.05%\n",
      "tensor(0.5274)\n",
      "With loss 0.44165778160095215.\n",
      "Validation Accuracy for network 214: 83.09%\n",
      "tensor(0.5936)\n",
      "With loss 0.5062140822410583.\n",
      "Validation Accuracy for network 215: 85.76%\n",
      "tensor(0.4570)\n",
      "With loss 0.46510618925094604.\n",
      "Validation Accuracy for network 216: 87.54%\n",
      "tensor(0.5269)\n",
      "With loss 0.4813539385795593.\n",
      "Validation Accuracy for network 217: 91.39%\n",
      "tensor(0.4858)\n",
      "With loss 0.4528083801269531.\n",
      "Validation Accuracy for network 218: 88.13%\n",
      "tensor(0.5450)\n",
      "With loss 0.44639188051223755.\n",
      "Validation Accuracy for network 219: 89.02%\n",
      "tensor(0.5869)\n",
      "With loss 0.504014253616333.\n",
      "Validation Accuracy for network 220: 85.76%\n",
      "tensor(0.5312)\n",
      "With loss 0.518622636795044.\n",
      "Validation Accuracy for network 221: 89.61%\n",
      "tensor(0.3607)\n",
      "With loss 0.5155502557754517.\n",
      "Validation Accuracy for network 222: 89.02%\n",
      "tensor(0.3925)\n",
      "With loss 0.47417405247688293.\n",
      "Validation Accuracy for network 223: 87.54%\n",
      "tensor(0.4855)\n",
      "With loss 0.46965527534484863.\n",
      "Validation Accuracy for network 224: 89.02%\n",
      "tensor(0.5268)\n",
      "With loss 0.5199447274208069.\n",
      "Validation Accuracy for network 225: 82.79%\n",
      "tensor(0.4936)\n",
      "With loss 0.48669156432151794.\n",
      "Validation Accuracy for network 226: 84.27%\n",
      "tensor(0.4513)\n",
      "With loss 0.4932418167591095.\n",
      "Validation Accuracy for network 227: 87.24%\n",
      "tensor(0.5240)\n",
      "With loss 0.4952693581581116.\n",
      "Validation Accuracy for network 228: 85.16%\n",
      "tensor(0.4370)\n",
      "With loss 0.5017265677452087.\n",
      "Validation Accuracy for network 229: 90.50%\n",
      "tensor(0.3567)\n",
      "With loss 0.4994717538356781.\n",
      "Validation Accuracy for network 230: 86.65%\n",
      "tensor(0.4260)\n",
      "With loss 0.45119574666023254.\n",
      "Validation Accuracy for network 231: 85.76%\n",
      "tensor(0.5853)\n",
      "With loss 0.4892188012599945.\n",
      "Validation Accuracy for network 232: 81.01%\n",
      "tensor(0.5344)\n",
      "With loss 0.4867013990879059.\n",
      "Validation Accuracy for network 233: 85.76%\n",
      "tensor(0.4341)\n",
      "With loss 0.4589185118675232.\n",
      "Validation Accuracy for network 234: 86.35%\n",
      "tensor(0.5741)\n",
      "With loss 0.48699161410331726.\n",
      "Validation Accuracy for network 235: 88.43%\n",
      "tensor(0.4610)\n",
      "With loss 0.5043824911117554.\n",
      "Validation Accuracy for network 236: 84.27%\n",
      "tensor(0.4405)\n",
      "With loss 0.49783727526664734.\n",
      "Validation Accuracy for network 237: 89.32%\n",
      "tensor(0.4447)\n",
      "With loss 0.4746144115924835.\n",
      "Validation Accuracy for network 238: 84.27%\n",
      "tensor(0.5456)\n",
      "With loss 0.493091881275177.\n",
      "Validation Accuracy for network 239: 87.83%\n",
      "tensor(0.4585)\n",
      "With loss 0.49299848079681396.\n",
      "Validation Accuracy for network 240: 86.05%\n",
      "tensor(0.4760)\n",
      "With loss 0.46185722947120667.\n",
      "Validation Accuracy for network 241: 85.16%\n",
      "tensor(0.6174)\n",
      "With loss 0.4903784692287445.\n",
      "Validation Accuracy for network 242: 80.42%\n",
      "tensor(0.5767)\n",
      "With loss 0.5165109634399414.\n",
      "Validation Accuracy for network 243: 84.27%\n",
      "tensor(0.5101)\n",
      "With loss 0.4964880049228668.\n",
      "Validation Accuracy for network 244: 84.87%\n",
      "tensor(0.4467)\n",
      "With loss 0.5138148069381714.\n",
      "Validation Accuracy for network 245: 85.46%\n",
      "tensor(0.4335)\n",
      "With loss 0.5165961980819702.\n",
      "Validation Accuracy for network 246: 81.01%\n",
      "tensor(0.4667)\n",
      "With loss 0.49773189425468445.\n",
      "Validation Accuracy for network 247: 86.65%\n",
      "tensor(0.4298)\n",
      "With loss 0.51451176404953.\n",
      "Validation Accuracy for network 248: 89.32%\n",
      "tensor(0.4209)\n",
      "With loss 0.48671481013298035.\n",
      "Validation Accuracy for network 249: 87.54%\n",
      "tensor(0.5009)\n",
      "With loss 0.4845229685306549.\n",
      "Validation Accuracy for network 250: 84.57%\n",
      "tensor(0.5609)\n",
      "With loss 0.5337045788764954.\n",
      "Validation Accuracy for network 251: 87.54%\n",
      "tensor(0.4164)\n",
      "With loss 0.467268168926239.\n",
      "Validation Accuracy for network 252: 84.87%\n",
      "tensor(0.5904)\n",
      "With loss 0.5128746628761292.\n",
      "Validation Accuracy for network 253: 84.87%\n",
      "tensor(0.4731)\n",
      "With loss 0.497382253408432.\n",
      "Validation Accuracy for network 254: 85.76%\n",
      "tensor(0.4869)\n",
      "With loss 0.493285208940506.\n",
      "Validation Accuracy for network 255: 89.32%\n",
      "tensor(0.3962)\n",
      "With loss 0.47947415709495544.\n",
      "Validation Accuracy for network 256: 89.02%\n",
      "tensor(0.4196)\n",
      "With loss 0.46595078706741333.\n",
      "Validation Accuracy for network 257: 87.24%\n",
      "tensor(0.4953)\n",
      "With loss 0.45963191986083984.\n",
      "Validation Accuracy for network 258: 87.24%\n",
      "tensor(0.5393)\n",
      "With loss 0.516822099685669.\n",
      "Validation Accuracy for network 259: 85.46%\n",
      "tensor(0.4563)\n",
      "With loss 0.4558931589126587.\n",
      "Validation Accuracy for network 260: 84.87%\n",
      "tensor(0.5405)\n",
      "With loss 0.5334453582763672.\n",
      "Validation Accuracy for network 261: 84.27%\n",
      "tensor(0.4699)\n",
      "With loss 0.4551263749599457.\n",
      "Validation Accuracy for network 262: 88.72%\n",
      "tensor(0.4585)\n",
      "With loss 0.5120800137519836.\n",
      "Validation Accuracy for network 263: 85.76%\n",
      "tensor(0.4389)\n",
      "With loss 0.5121908187866211.\n",
      "Validation Accuracy for network 264: 86.94%\n",
      "tensor(0.4282)\n",
      "With loss 0.4829467236995697.\n",
      "Validation Accuracy for network 265: 88.13%\n",
      "tensor(0.4764)\n",
      "With loss 0.5125953555107117.\n",
      "Validation Accuracy for network 266: 90.21%\n",
      "tensor(0.4244)\n",
      "With loss 0.5079779028892517.\n",
      "Validation Accuracy for network 267: 84.87%\n",
      "tensor(0.4448)\n",
      "With loss 0.5136382579803467.\n",
      "Validation Accuracy for network 268: 87.83%\n",
      "tensor(0.3707)\n",
      "With loss 0.5041274428367615.\n",
      "Validation Accuracy for network 269: 82.79%\n",
      "tensor(0.4634)\n",
      "With loss 0.48363810777664185.\n",
      "Validation Accuracy for network 270: 89.02%\n",
      "tensor(0.4197)\n",
      "With loss 0.44705086946487427.\n",
      "Validation Accuracy for network 271: 79.82%\n",
      "tensor(0.6881)\n",
      "With loss 0.4737580716609955.\n",
      "Validation Accuracy for network 272: 88.43%\n",
      "tensor(0.4363)\n",
      "With loss 0.46817106008529663.\n",
      "Validation Accuracy for network 273: 83.38%\n",
      "tensor(0.5553)\n",
      "With loss 0.5033010244369507.\n",
      "Validation Accuracy for network 274: 86.05%\n",
      "tensor(0.4503)\n",
      "With loss 0.4921475946903229.\n",
      "Validation Accuracy for network 275: 88.13%\n",
      "tensor(0.4294)\n",
      "With loss 0.5314107537269592.\n",
      "Validation Accuracy for network 276: 88.43%\n",
      "tensor(0.4057)\n",
      "With loss 0.44838225841522217.\n",
      "Validation Accuracy for network 277: 85.46%\n",
      "tensor(0.5359)\n",
      "With loss 0.502860426902771.\n",
      "Validation Accuracy for network 278: 84.57%\n",
      "tensor(0.4623)\n",
      "With loss 0.4707889258861542.\n",
      "Validation Accuracy for network 279: 89.32%\n",
      "tensor(0.5564)\n",
      "With loss 0.4907667934894562.\n",
      "Validation Accuracy for network 280: 89.32%\n",
      "tensor(0.4029)\n",
      "With loss 0.4638506770133972.\n",
      "Validation Accuracy for network 281: 84.57%\n",
      "tensor(0.5722)\n",
      "With loss 0.5119534134864807.\n",
      "Validation Accuracy for network 282: 85.46%\n",
      "tensor(0.4846)\n",
      "With loss 0.4535416066646576.\n",
      "Validation Accuracy for network 283: 87.83%\n",
      "tensor(0.5196)\n",
      "With loss 0.47981300950050354.\n",
      "Validation Accuracy for network 284: 86.94%\n",
      "tensor(0.4903)\n",
      "With loss 0.49960944056510925.\n",
      "Validation Accuracy for network 285: 82.49%\n",
      "tensor(0.5412)\n",
      "With loss 0.47849947214126587.\n",
      "Validation Accuracy for network 286: 85.16%\n",
      "tensor(0.4920)\n",
      "With loss 0.47466549277305603.\n",
      "Validation Accuracy for network 287: 85.16%\n",
      "tensor(0.5496)\n",
      "With loss 0.48638975620269775.\n",
      "Validation Accuracy for network 288: 86.94%\n",
      "tensor(0.4293)\n",
      "With loss 0.49332067370414734.\n",
      "Validation Accuracy for network 289: 84.87%\n",
      "tensor(0.4761)\n",
      "With loss 0.45955854654312134.\n",
      "Validation Accuracy for network 290: 87.24%\n",
      "tensor(0.6073)\n",
      "With loss 0.4688574969768524.\n",
      "Validation Accuracy for network 291: 87.24%\n",
      "tensor(0.5149)\n",
      "With loss 0.5075809359550476.\n",
      "Validation Accuracy for network 292: 88.13%\n",
      "tensor(0.4385)\n",
      "With loss 0.5107992887496948.\n",
      "Validation Accuracy for network 293: 86.65%\n",
      "tensor(0.4253)\n",
      "With loss 0.5331555604934692.\n",
      "Validation Accuracy for network 294: 86.65%\n",
      "tensor(0.3432)\n",
      "With loss 0.48437345027923584.\n",
      "Validation Accuracy for network 295: 82.20%\n",
      "tensor(0.5497)\n",
      "With loss 0.5404043793678284.\n",
      "Validation Accuracy for network 296: 86.05%\n",
      "tensor(0.4062)\n",
      "With loss 0.47667619585990906.\n",
      "Validation Accuracy for network 297: 91.10%\n",
      "tensor(0.5146)\n",
      "With loss 0.5012100338935852.\n",
      "Validation Accuracy for network 298: 90.80%\n",
      "tensor(0.4324)\n",
      "With loss 0.48068052530288696.\n",
      "Validation Accuracy for network 299: 90.50%\n",
      "tensor(0.4426)\n",
      "With loss 0.49541035294532776.\n",
      "Validation Accuracy for network 300: 87.54%\n",
      "tensor(0.4403)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n=700\n",
    "    index_e=0.9\n",
    "    r        = int(n ** index_e)\n",
    "    B        = 300            # or your B\n",
    "    p        = 10           # or your p\n",
    "    GLM_name = \"Bernoulli\"  # or your mode  \n",
    "    folder = 'resultspart8'      \n",
    "    X_maintest = torch.normal(0.0, 1.0, size=(80, 2))\n",
    "\n",
    "\n",
    "    X_noisetest = torch.normal(0.0, 1, size=(80, p - 2))\n",
    "\n",
    "\n",
    "    xtest= torch.cat([X_maintest, X_noisetest], dim=1)\n",
    "\n",
    "    Alloutputs,_,_,_=run_one_repeat(1, n, r, B, p, GLM_name, f_1, xtest)\n",
    "\n",
    "    # Parallel \n",
    "    \n",
    "\n",
    "    # # 解包并 stack\n",
    "    # Bf0_tensor = torch.stack([res[0] for res in results])  # [100, ntest]\n",
    "    # Bf1_tensor = torch.stack([res[1] for res in results])\n",
    "    # Bf2_tensor = torch.stack([res[2] for res in results])\n",
    "\n",
    "    # # 保存到 CSV\n",
    "    # df_bf0 = pd.DataFrame(Bf0_tensor.numpy())\n",
    "    # df_bf1 = pd.DataFrame(Bf1_tensor.numpy())\n",
    "    # df_bf2 = pd.DataFrame(Bf2_tensor.numpy())\n",
    "\n",
    "    # fn0 = f\"{folder}/{GLM_name}fBf1n{n}p{p}B{B}r{r}.csv\"\n",
    "    # fn1 = f\"{folder}/{GLM_name}sdf1nn{n}p{p}B{B}r{r}.csv\"\n",
    "    # fn2 = f\"{folder}/{GLM_name}sdcrtf1nn{n}p{p}B{B}r{r}.csv\"\n",
    "    # df_bf0.to_csv(fn0, index=False, header=False)\n",
    "    # df_bf1.to_csv(fn1, index=False, header=False)\n",
    "    # df_bf2.to_csv(fn2, index=False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.8063,  0.2619,  0.5171,  0.8939, -1.3791, -0.8618,  0.4825,  1.5649,\n",
       "         0.9376,  0.0424, -0.6257, -0.2455, -0.8058,  0.1625,  0.5295,  0.4818,\n",
       "        -0.5962,  0.4939,  0.7980,  0.2888,  0.6504,  0.0744,  0.5181,  0.2651,\n",
       "        -1.6699,  1.1180,  1.6422,  2.0496, -0.5767,  0.6938, -0.0819,  1.1401,\n",
       "         1.6230, -0.4863,  1.1102,  1.0617, -0.8690,  0.7609,  0.4084,  2.0006,\n",
       "         1.2923, -0.8976, -0.5373,  0.1594, -0.4801,  0.7277,  0.7688,  0.6641,\n",
       "         1.3489, -0.0705,  3.1907,  0.7392, -0.1738,  1.7027, -1.1580,  2.1217,\n",
       "        -0.4740, -1.9093,  1.1694,  2.2796, -0.4240, -1.6905,  0.2740, -0.8390,\n",
       "         1.6326, -1.2726, -1.0172, -1.5486,  1.0661, -0.0586,  1.5009, -0.6243,\n",
       "        -2.0294, -0.0086,  0.2764,  0.8557,  0.6513,  1.2709,  1.2008,  0.3941])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_1(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1733)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(Alloutputs[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0562, 1.1230, 1.7767, 1.2957, 1.5559, 0.8839, 0.3628, 0.5016, 0.9728,\n",
       "        1.4255, 1.5023, 1.8171, 1.4638, 1.0234, 1.3879, 1.4350, 1.4836, 1.7370,\n",
       "        1.2522, 0.7897, 1.6181, 1.1925, 0.6057, 0.7338, 1.5532, 0.6743, 0.7188,\n",
       "        1.8820, 1.0505, 0.8446, 1.9298, 1.5096, 1.1486, 1.4143, 1.1480, 1.6762,\n",
       "        0.3114, 1.5517, 1.7144, 0.9630, 1.2307, 0.6786, 0.7907, 0.8659, 0.9182,\n",
       "        0.9024, 0.9969, 0.6894, 1.4113, 1.5613, 0.9884, 1.4608, 1.2982, 1.6021,\n",
       "        0.4357, 1.4758, 1.4865, 1.2261, 1.2036, 1.8544, 1.0449, 1.2547, 0.7205,\n",
       "        1.0112, 1.0304, 1.3910, 0.9344, 0.8970, 0.7439, 0.7663, 0.9542, 1.4841,\n",
       "        1.7092, 0.7985, 1.7694, 1.1516, 1.0281, 1.0320, 1.2865, 0.8410, 0.8525,\n",
       "        0.8000, 1.5401, 0.6836, 1.0957, 1.4955, 1.2212, 1.5753, 1.2497, 1.3411,\n",
       "        0.7965, 0.7978, 0.7683, 1.6513, 0.6231, 0.9987, 1.5880, 1.0434, 1.9219,\n",
       "        1.2309, 1.5853, 1.2220, 0.7072, 1.3820, 1.1307, 1.0549, 0.7863, 0.6644,\n",
       "        0.9278, 1.3546, 1.2239, 1.6044, 1.7076, 0.9824, 1.0638, 0.3071, 1.3813,\n",
       "        0.5874, 1.8632, 1.0731, 1.6262, 0.7270, 1.5918, 1.0503, 0.8610, 1.2556,\n",
       "        1.2049, 1.6660, 1.7092, 0.9652, 0.6981, 1.5678, 1.6071, 1.5754, 1.5944,\n",
       "        1.1924, 1.7633, 1.0602, 0.9930, 1.4780, 0.6918, 1.0261, 1.4367, 1.8640,\n",
       "        0.5863, 0.4752, 0.6535, 1.6791, 1.9286, 0.9037, 0.6065, 0.7682, 0.6041,\n",
       "        0.6164, 1.5875, 1.4186, 0.5643, 1.6922, 1.4428, 0.7923, 1.3643, 1.8972,\n",
       "        1.1063, 0.7618, 1.0923, 0.9256, 0.6709, 0.7369, 0.4361, 1.8856, 1.3679,\n",
       "        0.8685, 1.4560, 0.5926, 0.6216, 1.4855, 0.9616, 0.2946, 1.5802, 0.6206,\n",
       "        0.9603, 1.3425, 1.0368, 0.6378, 1.0946, 0.8587, 1.6582, 1.3076, 0.9573,\n",
       "        1.1674, 1.0009, 1.4157, 0.5331, 0.4358, 0.9970, 0.7067, 1.0590, 0.8440,\n",
       "        0.8140, 0.7959, 0.9652, 1.1570, 1.0369, 1.1103, 1.0872, 1.0489, 1.4352,\n",
       "        0.6123, 1.0812, 1.0039, 2.1879, 1.4242, 2.0702, 1.7733, 1.5078, 1.1463,\n",
       "        1.1142, 1.5309, 1.7762, 1.1617, 1.2963, 0.9780, 1.3578, 1.5221, 1.4981,\n",
       "        1.1019, 0.7629, 1.0981, 1.2586, 0.4292, 1.7870, 1.0988, 1.7004, 1.3143,\n",
       "        0.9136, 0.4562, 0.6590, 1.0348, 0.5784, 0.5961, 1.2963, 0.7236, 1.1597,\n",
       "        0.8834, 1.4977, 1.5187, 1.4048, 0.7377, 1.7183, 1.6040, 1.3000, 1.1980,\n",
       "        1.5006, 0.6174, 1.5182, 1.1299, 1.7906, 1.2634, 1.2897, 1.1195, 1.1279,\n",
       "        1.5671, 1.1839, 0.4862, 1.9491, 1.5201, 1.2398, 1.5644, 1.5261, 0.7503,\n",
       "        1.2874, 1.3533, 1.0527, 1.0076, 1.4830, 0.3394, 1.0712, 1.6699, 1.8646,\n",
       "        1.4087, 1.4682, 1.1202, 1.4935, 1.1488, 1.0648, 1.9150, 1.7931, 1.5088,\n",
       "        0.9451, 1.5075, 0.7619, 1.2446, 1.3971, 1.1921, 0.7350, 0.8660, 2.0118,\n",
       "        0.6962, 1.2725, 1.6780])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alloutputs[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1731)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j=2\n",
    "maintain=0.025\n",
    "\n",
    "torch.mean(Alloutputs[j,:][(Alloutputs[j,:]>torch.quantile(Alloutputs[j,:],maintain))&(Alloutputs[j,:]<torch.quantile(Alloutputs[j,:],1-maintain))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
