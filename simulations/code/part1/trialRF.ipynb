{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import argparse\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# folder_path = 'model1/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "# os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def f_1(x):\n",
    "    return x[:, 0] + 0.25 * x[:, 1] ** 2+0.1*torch.tanh(0.5*x[:,2]-0.3)\n",
    "\n",
    "# def f_2(x):\n",
    "#     return x[:,0]**2/2-abs(x[:,4]*x[:,9])+torch.exp(0.1*x[:,14])-torch.sin(3.141592*x[:,19])\n",
    "# def f_2(x):\n",
    "#     return 2*(x[:,0]>0)-2*(x[:,0]<0)\n",
    "\n",
    "def poisson_loss(logits,y_true):\n",
    "    \"\"\"\n",
    "    Compute the Poisson negative log-likelihood loss.\n",
    "    \n",
    "    Args:\n",
    "        y_true (torch.Tensor): True labels (0, 1, 2, ...), shape (batch_size,).\n",
    "        logits (torch.Tensor): Output of the DNN (before exponentiation), shape (batch_size,).\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Mean negative log-likelihood loss over the batch.\n",
    "    \"\"\"\n",
    "    # Convert logits to λ(x) = e^logits\n",
    "    lambda_pred = torch.exp(logits)\n",
    "    \n",
    "    # Compute the negative log-likelihood\n",
    "    loss = lambda_pred - y_true * logits  # Equivalent to λ(x) - Y * log(λ(x))\n",
    "    return loss.mean()\n",
    "\n",
    "class SampleSet:\n",
    "    def __init__(self, n, p,f_X,module='Bernoulli', mean=0, std=1,trials=None):\n",
    "        \"\"\"\n",
    "        Initializes the SampleSet with n samples and p features for X.\n",
    "        Y is generated based on the conditional probability P(Y=1|X).\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "        self.p = p\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.r=None\n",
    "        self.B=None\n",
    "        self.module=module\n",
    "        # Generate X with dimension (n, p)\n",
    "        X_main = torch.normal(0.0, 1.0, size=(n, 2))\n",
    "        X_noise = torch.normal(0.0, 1, size=(n, p - 2))\n",
    "        self.X = torch.cat([X_main, X_noise], dim=1)\n",
    "        # self.X=2*torch.rand((n, p)) -2\n",
    "        self.subtrain=None\n",
    "        self.subval=None\n",
    "        self.counts=None\n",
    "        self.trials=trials\n",
    "        self.f_X=f_X\n",
    "        # Compute z = f(X) and use it to generate P(Y=1|X) and Y\n",
    "        self.z = self._compute_z(self.X)  # Save z values (f(X))\n",
    "        self.Y = self._generate_Y(self.z)\n",
    "    \n",
    "    def _compute_z(self, X):\n",
    "        return   self.f_X(X)\n",
    "    \n",
    "    def _generate_Y(self, z):\n",
    "        if self.module=='Bernoulli':\n",
    "            # Generate Y as a Bernoulli random variable with probability P(Y=1|X)\n",
    "            P_Y_given_X = 1 / (1 + torch.exp(-z))\n",
    "            Y = torch.bernoulli(P_Y_given_X)\n",
    "        elif self.module=='Gaussian':\n",
    "            Y = torch.normal(mean=z, std=1.0)\n",
    "        elif self.module=='Binomial':\n",
    "            if self.trials is None:\n",
    "                self.trials = torch.randint(low=5, high=6, size=(self.n,))  \n",
    "\n",
    "            P_Y_given_X = 1 / (1 + torch.exp(-z)) # Ensure the rate parameter is positive\n",
    "            Y = torch.binomial(self.trials.float(), P_Y_given_X)\n",
    "\n",
    "        elif self.module == 'Poisson':\n",
    "        # Generate Y as a Poisson random variable with rate parameter (lambda) equal to exp(z)\n",
    "            rate_param = torch.log(1+torch.exp(z))   # Ensure the rate parameter is positive\n",
    "            Y = torch.poisson(rate_param)\n",
    "        else:\n",
    "        # Raise an error for unsupported modules\n",
    "            raise ValueError(f\"Unsupported module type: {self.module}. Expected one of: 'Bernoulli', 'Gaussian', 'Exponential', 'Poisson'.\")\n",
    "        return Y\n",
    "    \n",
    "    def get_z(self):\n",
    "        \"\"\"Returns the computed z values, which represent f(X).\"\"\"\n",
    "        return self.z\n",
    "    \n",
    "    def get_sample_set(self):\n",
    "        \"\"\"Returns the main sample set (X, Y).\"\"\"\n",
    "        return self.X, self.Y\n",
    "    \n",
    "    def get_sub_samples_with_validation(self, B, r):\n",
    "        \"\"\"\n",
    "        Generates B sub-sample sets, each containing r samples randomly selected \n",
    "        from the main sample set, along with corresponding validation sets.\n",
    "        \n",
    "        Also counts the number of times each index is selected across all B sub-samples.\n",
    "        \n",
    "        Returns:\n",
    "            train_samples: List of tuples, each containing (train_X, train_Y, train_indices)\n",
    "            validation_samples: List of tuples, each containing (val_X, val_Y, val_indices)\n",
    "            selection_counts: Dictionary with counts of each index's appearance in the B sub-samples.\n",
    "        \"\"\"\n",
    "        train_samples = []\n",
    "        validation_samples = []\n",
    "        selection_counts = Counter({i: 0 for i in range(self.n)})  # To track appearances of each index\n",
    "        indices = torch.arange(self.n)\n",
    "        self.B=B\n",
    "        self.r=r\n",
    "        for _ in range(B):\n",
    "            # Randomly select r unique indices for the sub-sample\n",
    "            selected_indices = indices[torch.randperm(self.n)[:r]]\n",
    "            \n",
    "            # Update selection count for each index\n",
    "            selection_counts.update(selected_indices.tolist())\n",
    "            \n",
    "            # Get validation indices (those not in selected_indices)\n",
    "            val_indices = torch.tensor([i for i in indices if i not in selected_indices])\n",
    "\n",
    "            # Separate sub-sample and validation sets, including original indices\n",
    "            X_sub = self.X[selected_indices]\n",
    "            Y_sub = self.Y[selected_indices]\n",
    "            X_val = self.X[val_indices]\n",
    "            Y_val = self.Y[val_indices]\n",
    "            \n",
    "            # Append to train_samples and validation_samples lists\n",
    "            train_samples.append((X_sub, Y_sub, selected_indices))\n",
    "            validation_samples.append((X_val, Y_val, val_indices))\n",
    "        self.subtrain=train_samples\n",
    "        self.subval=validation_samples\n",
    "        self.counts=dict(selection_counts)\n",
    "        return train_samples, validation_samples, dict(selection_counts)\n",
    "    \n",
    "    def save(self, file_path):\n",
    "        \"\"\"Saves the SampleSet instance to a file.\"\"\"\n",
    "        torch.save(self, file_path)\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(file_path):\n",
    "        \"\"\"Loads a SampleSet instance from a file.\"\"\"\n",
    "        return torch.load(file_path)\n",
    "\n",
    "\n",
    "\n",
    "def clear_folder(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"folder {folder_path} does not exist\")\n",
    "        return\n",
    "\n",
    "\n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "\n",
    "        if os.path.isfile(item_path):\n",
    "            os.remove(item_path)\n",
    "\n",
    "        elif os.path.isdir(item_path):\n",
    "            shutil.rmtree(item_path)\n",
    "\n",
    "\n",
    "\n",
    "def train_multiple_RF(sample_set, mode=\"Bernoulli\"):\n",
    "    train_samples, validation_samples, selection_counts = sample_set.subtrain, sample_set.subval, sample_set.counts\n",
    "    \n",
    "    models = []  \n",
    "    for i, (train_data, val_data) in enumerate(zip(train_samples, validation_samples)):\n",
    "        print(i)\n",
    "        X_sub, Y_sub, _ = train_data\n",
    "        X_val, Y_val, _ = val_data\n",
    "        if mode==\"Bernoulli\":\n",
    "\n",
    "            rf = RandomForestClassifier(n_estimators=200,criterion=\"entropy\",   \n",
    "                 random_state=42)\n",
    "            \n",
    "            rf.fit(X_sub, Y_sub)\n",
    "\n",
    "            # 预测概率\n",
    "            models.append(rf)\n",
    "            # p_hat = (rf.predict_proba(X_val)[:, 1])[0:30]\n",
    "            # print('hat:',p_hat)\n",
    "            # p_true=torch.sigmoid(f_1(X_val))[0:30]\n",
    "            # print('ture:',p_true)\n",
    "\n",
    "        elif mode == \"Poisson\":\n",
    "            rf = RandomForestRegressor(n_estimators=200,criterion=\"poisson\", random_state=42)\n",
    "            rf.fit(X_sub.numpy(), Y_sub.numpy()) \n",
    "            models.append(rf)\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # Validation performance (optional)\n",
    "\n",
    "\n",
    "    \n",
    "    return models\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ensemble_predict_batch_f(Xtest, models, sample_set):\n",
    "    ntest = Xtest.shape[0]\n",
    "    n = sample_set.n       # Total number of original samples\n",
    "    r = sample_set.r       # Size of each sub-sample\n",
    "    B = len(models)      # Number of sub-samples (number of neural networks)\n",
    "    mtype=sample_set.module\n",
    "    # Collect logits from all networks for the test set (shape: [ntest, B])\n",
    "    all_outputs = torch.zeros(ntest, B)\n",
    "    if mtype == \"Bernoulli\":   \n",
    "        for j, net in enumerate(models):\n",
    "            p_hat = net.predict_proba(Xtest)[:, 1]   # ndarray\n",
    "            print(p_hat)\n",
    "            all_outputs[:, j] = torch.tensor(p_hat)\n",
    "            # \n",
    "\n",
    "    elif mtype == \"Poisson\":  \n",
    "        for j, net in enumerate(models):              \n",
    "            lam_hat = net.predict(Xtest)            # ndarray\n",
    "            all_outputs[:, j] = torch.tensor(lam_hat)\n",
    "            # all_outputs=torch.log(all_outputs)\n",
    "\n",
    "    if mtype == \"Bernoulli\":  \n",
    "        all_outputs=torch.log(all_outputs/(1-all_outputs))\n",
    "    elif mtype == \"Poisson\":  \n",
    "        all_outputs=torch.log(all_outputs)\n",
    "\n",
    "\n",
    "    # Compute inclusion counts J_bji and mean inclusion J_dot_i for each training index i\n",
    "    J_bji = sample_set.counts  # Dict mapping i -> count of i in each sub-sample\n",
    "    J_dot_i = {i: J_bji[i] / B for i in range(n)}\n",
    "\n",
    "    # Ensemble mean prediction for each test sample\n",
    "    hatf_B = all_outputs.mean(dim=1)  # Shape: [ntest]\n",
    "\n",
    "    # Initialize accumulators for variance correction terms\n",
    "    sum_V2 = torch.zeros(ntest)      # Accumulate sum of hat_V_i^2 over i\n",
    "    sum_Zdiff2 = torch.zeros(ntest)  # Accumulate sum of (Z_ji - hat_V_i)^2 over i and j\n",
    "\n",
    "    # Loop over each original data index i\n",
    "    for i in range(n):\n",
    "        # Gather Z_{b_j i}(x*) for all sub-samples j (shape: [B, ntest])\n",
    "        Zs = torch.zeros(B, ntest)\n",
    "        for j in range(B):\n",
    "            _, _, Jbjicount = sample_set.subtrain[j]\n",
    "            in_subset = 1.0 if (i in Jbjicount) else 0.0\n",
    "            deviations = all_outputs[:, j] - hatf_B  # Shape: [ntest]\n",
    "            Zs[j] = (in_subset - J_dot_i[i]) * deviations\n",
    "\n",
    "        # Compute hat_V_i(x*) and accumulate\n",
    "        hat_V_i = Zs.mean(dim=0)  # Shape: [ntest]\n",
    "        sum_V2 += hat_V_i.pow(2)\n",
    "        sum_Zdiff2 += (Zs - hat_V_i.unsqueeze(0)).pow(2).sum(dim=0)\n",
    "\n",
    "    # Correction factor: n(n-1)/(n-r)^2\n",
    "    factor = (n - 1) / n * (n / (n - r))**2\n",
    "\n",
    "    # Compute corrected variance terms\n",
    "    term1 = factor * sum_V2\n",
    "    term2 = factor * sum_Zdiff2 / (B * (B - 1))\n",
    "    var_f = term1 - term2          # Bias-corrected variance estimate\n",
    "\n",
    "    # Standard deviations\n",
    "    sd_f_raw = torch.sqrt(term1)       # Without bias correction\n",
    "    sd_f_correct = torch.sqrt(var_f)   # With bias correction\n",
    "\n",
    "\n",
    "    return all_outputs, [hatf_B, sd_f_raw, sd_f_correct]\n",
    "\n",
    "\n",
    "\n",
    "def run_one_repeat(rep_id, n, r, B, p, GLM_name, f_1, xtest):\n",
    "    # 每个 repeat 训练 B 个网络，最后做一次 ensemble 预测\n",
    "    ss = SampleSet(n, p, f_1, module=GLM_name)\n",
    "    ss.get_sub_samples_with_validation(B, r)\n",
    "\n",
    "    \n",
    "    models=train_multiple_RF(ss, mode=GLM_name)\n",
    "    _, Bf = ensemble_predict_batch_f(xtest, models, ss)\n",
    "    return Bf[0], Bf[1],Bf[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "[0.7   0.765 0.34  0.68  0.555 0.435 0.575 0.27  0.425 0.21  0.435 0.24\n",
      " 0.775 0.57  0.72  0.51  0.325 0.645 0.37  0.695 0.775 0.36  0.255 0.285\n",
      " 0.32  0.485 0.245 0.545 0.685 0.815 0.56  0.765 0.24  0.73  0.495 0.405\n",
      " 0.745 0.42  0.51  0.585 0.53  0.435 0.74  0.465 0.12  0.67  0.46  0.42\n",
      " 0.71  0.445 0.79  0.465 0.665 0.65  0.34  0.49  0.69  0.16  0.49  0.475\n",
      " 0.63  0.475 0.83  0.525 0.695 0.615 0.48  0.195 0.34  0.37  0.845 0.505\n",
      " 0.55  0.59  0.75  0.59  0.61  0.585 0.42  0.8  ]\n",
      "[0.56  0.595 0.26  0.56  0.6   0.39  0.62  0.4   0.43  0.245 0.48  0.145\n",
      " 0.695 0.575 0.54  0.515 0.57  0.655 0.68  0.505 0.775 0.405 0.215 0.46\n",
      " 0.365 0.61  0.52  0.735 0.435 0.69  0.525 0.555 0.375 0.525 0.4   0.41\n",
      " 0.6   0.525 0.39  0.735 0.655 0.395 0.73  0.54  0.255 0.65  0.485 0.445\n",
      " 0.79  0.4   0.72  0.415 0.36  0.75  0.405 0.485 0.49  0.31  0.45  0.535\n",
      " 0.64  0.415 0.71  0.51  0.605 0.515 0.675 0.225 0.7   0.505 0.815 0.45\n",
      " 0.45  0.515 0.765 0.7   0.585 0.66  0.455 0.67 ]\n",
      "[0.675 0.5   0.425 0.455 0.66  0.525 0.505 0.255 0.36  0.23  0.49  0.465\n",
      " 0.825 0.54  0.73  0.335 0.6   0.515 0.595 0.675 0.81  0.395 0.23  0.515\n",
      " 0.425 0.745 0.3   0.765 0.645 0.63  0.605 0.61  0.325 0.695 0.32  0.57\n",
      " 0.66  0.47  0.63  0.64  0.655 0.405 0.73  0.405 0.315 0.545 0.49  0.615\n",
      " 0.86  0.525 0.725 0.555 0.485 0.715 0.655 0.605 0.555 0.205 0.37  0.685\n",
      " 0.68  0.625 0.755 0.465 0.61  0.56  0.52  0.215 0.59  0.41  0.865 0.58\n",
      " 0.54  0.56  0.74  0.655 0.505 0.64  0.4   0.575]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--n\",     type=int,   required=True)\n",
    "    # parser.add_argument(\"--index\", type=float, required=True)\n",
    "    # args = parser.parse_args()\n",
    "    n=700\n",
    "    index_e=0.9\n",
    "\n",
    "######Constant Area#######\n",
    "    # n        = args.n\n",
    "    # index_e  = args.index\n",
    "    r        = int(n ** index_e)\n",
    "    B        = 3            # or your B\n",
    "    p        = 10           # or your p\n",
    "    GLM_name = \"Bernoulli\"  # or your mode      \n",
    "    folder = 'resultspart1'  \n",
    "    xtest    = torch.load(f\"xtest10.pt\")  # 预先生成并保存\n",
    "    ss = SampleSet(n, p, f_1, module=GLM_name)\n",
    "    ss.get_sub_samples_with_validation(B, r)\n",
    "\n",
    "    \n",
    "    Af, Bf = ensemble_predict_batch_f(xtest, models, ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.0645e-01,  5.2165e-01, -6.7051e-01,  2.7148e-01,  4.2988e-01,\n",
       "        -2.0290e-01,  2.7061e-01, -8.2407e-01, -3.8650e-01, -1.2196e+00,\n",
       "        -1.2718e-01, -1.0224e+00,  1.2037e+00,  2.4816e-01,  6.9981e-01,\n",
       "        -1.9521e-01, -1.4524e-02,  4.3275e-01,  2.0208e-01,  5.2483e-01,\n",
       "         1.3078e+00, -4.6213e-01, -1.1918e+00, -3.4004e-01, -5.3659e-01,\n",
       "         4.8647e-01, -6.3090e-01,  7.9364e-01,  3.7083e-01,  9.3839e-01,\n",
       "         2.5586e-01,  6.1617e-01, -7.9813e-01,  6.3944e-01, -3.9308e-01,\n",
       "        -1.5560e-01,  7.1363e-01, -1.1428e-01,  4.1637e-02,  6.4628e-01,\n",
       "         4.6744e-01, -3.5750e-01,  1.0117e+00, -1.2152e-01, -1.2805e+00,\n",
       "         5.0257e-01, -8.6789e-02, -2.5096e-02,  1.3452e+00, -1.7543e-01,\n",
       "         1.0796e+00, -8.7556e-02,  1.6758e-02,  8.7915e-01, -1.3563e-01,\n",
       "         1.0877e-01,  3.2700e-01, -1.2712e+00, -2.5763e-01,  2.7233e-01,\n",
       "         6.2045e-01,  2.2470e-02,  1.2022e+00, -4.6884e-05,  5.6575e-01,\n",
       "         2.5652e-01,  2.4363e-01, -1.3166e+00,  1.8266e-01, -2.9206e-01,\n",
       "         1.6787e+00,  4.7368e-02,  5.3448e-02,  2.2172e-01,  1.1083e+00,\n",
       "         6.1745e-01,  2.7022e-01,  5.2733e-01, -3.0291e-01,  7.9892e-01])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"--n\",     type=int,   required=True)\n",
    "    # parser.add_argument(\"--index\", type=float, required=True)\n",
    "    # args = parser.parse_args()\n",
    "    n=400\n",
    "    index_e=0.8\n",
    "\n",
    "######Constant Area#######\n",
    "    # n        = args.n\n",
    "    # index_e  = args.index\n",
    "    r        = int(n ** index_e)\n",
    "    B        = 1400            # or your B\n",
    "    p        = 10           # or your p\n",
    "    GLM_name = \"Poisson\"  # or your mode      \n",
    "    folder = 'resultspart1'  \n",
    "    xtest    = torch.load(f\"{folder}/xtest10.pt\")  # 预先生成并保存\n",
    "\n",
    "    repeats = 100\n",
    "\n",
    "    # Parallel \n",
    "    results = Parallel(n_jobs=20)(\n",
    "        delayed(run_one_repeat)(i, n, r, B, p, GLM_name, f_1, xtest)\n",
    "        for i in range(repeats)\n",
    "    )\n",
    "\n",
    "    # 解包并 stack\n",
    "    Bf0_tensor = torch.stack([res[0] for res in results])  # [100, ntest]\n",
    "    Bf1_tensor = torch.stack([res[1] for res in results])\n",
    "    Bf2_tensor = torch.stack([res[2] for res in results])\n",
    "\n",
    "    # 保存到 CSV\n",
    "    df_bf0 = pd.DataFrame(Bf0_tensor.numpy())\n",
    "    df_bf1 = pd.DataFrame(Bf1_tensor.numpy())\n",
    "    df_bf2 = pd.DataFrame(Bf2_tensor.numpy())\n",
    "\n",
    "    fn0 = f\"{folder}/{GLM_name}fBf1n{n}p{p}B{B}r{r}.csv\"\n",
    "    fn1 = f\"{folder}/{GLM_name}sdf1nn{n}p{p}B{B}r{r}.csv\"\n",
    "    fn2 = f\"{folder}/{GLM_name}sdcrtf1nn{n}p{p}B{B}r{r}.csv\"\n",
    "    df_bf0.to_csv(fn0, index=False, header=False)\n",
    "    df_bf1.to_csv(fn1, index=False, header=False)\n",
    "    df_bf2.to_csv(fn2, index=False, header=False)\n",
    "\n",
    "    print(f\"Done n={n}, index={index_e}, saved {fn0}, {fn1},{fn2}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
